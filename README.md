# ğŸŒŠ Caspian Seismic Data Platform
**End-to-End Data Vault â†’ Analytics â†’ Dashboard Pipeline**

---

## ğŸ“Œ Project Overview

This project implements a full data engineering pipeline for seismic survey data from the Caspian basin.
The objective is to recover corrupted data files, preserve full historical provenance, and transform the data
into analytics-ready structures for operational and strategic decision-making.

The solution follows **Data Vault 2.0** methodology and delivers:
- Incremental ingestion
- Full historical tracking
- Analytics marts
- Business dashboards

---

## ğŸ§± Architecture Overview

Raw Files (SGX / Parquet)  
â†’ Recovery & Decoding  
â†’ Raw Vault (Hubs / Links / Satellites)  
â†’ Incremental Ingest (Apache Airflow)  
â†’ Analytics Layer (Star Schema)  
â†’ Visualization (Metabase)

---

## ğŸ› ï¸ Technology Stack

- **Database:** PostgreSQL  
- **Orchestration:** Apache Airflow  
- **Containers:** Docker, Docker Compose  
- **Modeling:** Data Vault 2.0  
- **Analytics:** Dimensional Modeling (Star Schema)  
- **Visualization:** Metabase  
- **Languages:** Python, SQL  
- **Environment:** Linux VM  

---

---

## ğŸ§© Data Vault Model

### Hubs
- hub_well
- hub_sensor
- hub_survey_type

Store immutable business keys.

### Links
- link_sensor_well
- link_sensor_survey_type
- link_survey_type_well

Represent relationships between business entities.

### Satellites
- sat_link_sensor_well_readings

Store all historical measurements and metadata:
- amplitude
- timestamp
- record_source
- checksum
- load_dts

No transformations or business rules are applied at this layer.

---

## ğŸ” Incremental Ingestion (Apache Airflow)

DAG: **raw_vault_incremental_ingest**

Steps:
1. Scan parquet directories
2. Detect new or changed files (file_manifest)
3. Process valid data
4. Track missing files

Control tables:
- raw_vault.file_manifest
- raw_vault.rejected_records

---

## ğŸ“Š Analytics Layer

### Dimensions
- dim_well
- dim_sensor
- dim_time
- dim_source_format
- dim_survey_type

### Fact Table
- fact_sensor_readings

Only valid, fully mapped records are loaded into analytics.

---

## ğŸ“ˆ Analytics Marts

### mart_well_performance
- total_readings
- avg_amplitude
- data_quality_pct
- breakdown by source_format

### mart_sensor_analysis
- total_readings
- avg_amplitude
- data_quality_pct  
(sensor_id used as sensor type)

### mart_survey_summary
- wells_surveyed
- total_readings
- avg_amplitude
- time coverage
- breakdown by source_format

---

## ğŸ“Š Dashboards (Metabase)

Dashboards include:
- Wells geospatial map
- Well activity over time
- Amplitude distributions
- Sensor reliability analysis
- Survey coverage summaries
- Data quality indicators

---

## ğŸš€ How to Run

Start services:
```bash
docker compose up -d

